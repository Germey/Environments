# 1.8 爬虫框架的安装

我们直接用 Requests、Selenium 等库写爬虫，如果爬取量不是太大，速度要求不高，是完全可以满足需求的。但是写多了会发现其内部许多代码和组件是可以复用的，如果我们把这些组件抽离出来，将各个功能模块化，就慢慢会形成一个框架雏形，久而久之，爬虫框架就诞生了。

利用框架我们可以不用再去关心某些功能的具体实现，只需要去关心爬取逻辑即可。有了它们，可以大大简化代码量，而且架构也会变得清晰，爬取效率也会高许多。所以如果对爬虫有一定基础，上手框架是一种好的选择。

本书主要介绍的爬虫框架有PySpider和Scrapy，本节我们来介绍一下 PySpider、Scrapy 以及它们的一些扩展库的安装方式。